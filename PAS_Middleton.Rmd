---
title: "Practical Statistical Inference"
subtitle: "Putting data first"
author: "Kevin Middleton"
date: "2018/02/17"
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "macros.js"
    css: ["default.css"]

---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
library(knitr)
library(wesanderson)
library(cowplot)
```

class: center, middle, inverse, title-slide

# Practical Bayesian Inference

## The new (old) statistics

### Kevin M. Middleton, Ph.D.

#### Department of Pathology & Anatomical Sciences<br>University of Missouri School of Medicine

<br>

![:scale 70%](https://i.imgur.com/9btotx8.png)

---

## Goals for today

- Think about why we use traditional (frequentist) statistics
- Think about how we make decisions everyday
- Combine the two into a statistical framework
- How we use these approaches in my lab to make draw conclusions based on data

--

## Thinking about how trainees learn statistics

- Undergraduates
    - Mostly not required for undergraduate science majors
- Graduate school
    - One or more courses
- Medical school
    - Someday to be an MCAT prerequisite
    - IPC4 initially at MU via Epidemiology

---
class: center, middle

## Frequentist approaches

![:scale 80%](https://i.imgur.com/guHfGWo.png)

---

## Assumptions

- Homogeneity of variances
- Normality of residuals
- Large sample sizes
- Repeated experiments

---

## What do frequentist approaches really mean?

- NHST
- Confidence intervals

---

## (Re)emergence of Bayesian inference

---

## Bayes history

---

## In praise of gambling

.center[
![:scale 44%](https://i.imgur.com/C4LOeAK.jpg)![:scale 40%](https://i.imgur.com/x0d2CX4.jpg)

Abraham de Moivre
]

---

## In praise of gambling

.pull-left[
![:scale 90%](https://i.imgur.com/EyuUNeB.jpg)
]

.pull-right[
What is the probability of getting dealt 4 aces in a poker hand?
]

$$\frac{4}{52}\frac{3}{51}\frac{2}{50}\frac{1}{49}\frac{48}{48}\times 5 = 0.000018 = 0.0018\%$$

.center[
(There is nothing special about aces.)
]

---

## Inverse probability

> Given that a poker player has dealt three hands in a row with four aces, *what is the probability that the dealer is cheating*?

![:scale 33%](https://i.imgur.com/EyuUNeB.jpg)![:scale 33%](https://i.imgur.com/EyuUNeB.jpg)![:scale 33%](https://i.imgur.com/EyuUNeB.jpg)

--

$$0.000018^3 = 0.00000000000058\%$$

---

## Thomas Bayes

.center[
![:scale 44%](https://i.imgur.com/LlYJtH4.jpg)

(Probably not Thomas Bayes)
]

---

## Pierre Simon Laplace

.center[
![:scale 44%](https://i.imgur.com/eWHLAUB.jpg)

]

---

## A little math

$$P(a,b) = P(a|b)P(b)$$

$$P(a,b) = P(b|a)P(a)$$

$$P(b|a) = \frac{P(a|b)P(b)}{P(a)}$$
---

## For scientific inference

$$P(b|a) = \frac{P(a|b)P(b)}{P(a)}$$

$$P(hypothesis|data) = \frac{P(data|hypo)P(hypo)}{P(data)}$$

$$P(hypothesis|data) = \frac{P(data|hypo)P(hypo)}{\Sigma_{h'\in H}P(d'|h')P(h')}$$

Posterior probability is the product of the likelihood and prior normalized by their sum (to make the probability sum to 1).

---

## Rolling dice

$$P(a,b) = P(a|b)P(b)$$

$$P(roll~1, roll~1) = \frac{1}{6} \cdot \frac{1}{6} = \frac{1}{36}$$

---

## Your brain as a Bayesian engine

.pull-left[Two movies open the same week.

**What is the probability that each will earn $200 million?**
]

.pull-right[
![:scale 80%](https://i.imgur.com/XVU4S2T.jpg)
]

---

## Your brain as a Bayesian engine

.pull-left[Two movies open the same week.

**What is the probability that each will earn $200 million?**
]

.pull-right[
![:scale 80%](https://i.imgur.com/XVU4S2T.jpg)
]

1. One movie earned $100 million in the first weekend
2. The other movie earned $1 million in the first weekend

---

## Patient with chest pain

Patient presents with substernal chest pain on exertion, gradually getting worse over 1 month. Pain not associated with meals. No nausea/vomiting.

> What's the diagnosis?

---

## Patient with chest pain

**23 y/o female patient with history of anxiety** presents with substernal chest pain on exertion, gradually getting worse over 1 month. Pain not associated with meals. No nausea/vomiting.

> What's the diagnosis?

---

## Patient with chest pain

**67 y/o male patient with history of hypertension, DM, and hyperlipidemia** presents with substernal chest pain on exertion, gradually getting worse over 1 month. Pain not associated with meals. No nausea/vomiting.

> What's the diagnosis?

---

## Bayesian clinical reasoning

**Data**: Your patient has a cough

**Hypotheses**:

--

1. Patient has a cold

--

2. Patient has lung cancer

--

3. Patient has gastroenteritis

---

# Priors

Some reasonable priors:

--

1. Cold (lifetime risk ~99%)

--

2. Lung cancer (lifetime risk ~6%)

--

3. Gastroenteritis (lifetime risk ~99%)


---

# Posterior

1. High prior x high likelihood = high posterior probability

--

2. Low prior x low likelihood = low posterior probability

--

3. High prior x low likelihood = low posterior probability

---

## A patient with the pox

.center[
![scale 100%](https://i.imgur.com/WITJSIT.jpg)
]

---

## Pox: Chicken or Small?

.center[
![scale 70%](https://i.imgur.com/bbT8vYn.jpg)
]

---

## Pox: Chicken or Small?

.center[
![scale 70%](https://i.imgur.com/fCthUjq.jpg)
]

---

## Familywise error rate

```{r echo=FALSE, fig.height=6, fig.width=10}
calcFWER <- function(k, alpha){
  return(round(1 - (1 - alpha) ^ k, 3))
}
k <- seq(1, 200, by = 1)
alphas <- c(0.05, 0.01, 0.001)
out <- matrix(NA, ncol = length(alphas))
for (i in alphas) {
  FWER <- calcFWER(k, i)
  alpha <- rep(i, times = length(k))
  tmp <- cbind(alpha, k, FWER)
  out <- rbind(out, tmp)
}
FWERs <- as.data.frame(out)
FWERs$alpha <- as.factor(FWERs$alpha)
ggplot(FWERs, aes(x = k, y = FWER, color = alpha)) +
  geom_hline(yintercept = 1, lty = "dotted") +
  geom_path(lwd = 2) +
  ylab("Familywise Error Rate") +
  xlab("Number of P-values") +
  scale_color_manual(values = wes_palette("Moonrise3"),
                     name = "Alpha",
                     breaks = c("0.05", "0.01", "0.001")) +
  theme(text = element_text(size = 20),
        axis.text = element_text(size = 18))

```

---

## Bayesian decisions

> The only real novelty on the Bayesian approach lies in the fact that it provides a *formal mechanism* for taking account of these preferences and weights instead of leaving it to the decision maker's unaided intuition to determine their implications. We believe, however, that without this formalization decisions under uncertainty have been and will remain essentially arbitrary, as evidenced by the fact that, in most statistical practice, consequences and performance characteristics receive mere lip service while decisions are actually made by treating the numbers .05 and .95 with the same superstitious awe that is usually reserved for the number 13.

Raiffa and Schlaifer, 1961 *Applied Statistical Decision Theory*

---

## Gators

![scale 80%](https://i.imgur.com/rBXE5Hv.png)

---

## Gator models

---

## Gators

![scale 80%](https://i.imgur.com/heVWzGI.png)
